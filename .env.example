# .env.example
# Mira Environment Configuration
# Copy to ~/.mira/.env and fill in your values
#
# Configuration is loaded once at startup from ~/.mira/.env

# ═══════════════════════════════════════════════════════════════════════════════
# API Keys
# ═══════════════════════════════════════════════════════════════════════════════

# DeepSeek - LLM provider for background intelligence
# Get from: https://platform.deepseek.com/api_keys
# DEEPSEEK_API_KEY=sk-your-deepseek-key-here

# Zhipu GLM - Alternative LLM provider (GLM-4.7 via coding endpoint)
# Get from: https://z.ai (coding plan)
# ZHIPU_API_KEY=your-zhipu-api-key-here

# OpenAI - Recommended for semantic search (embeddings via text-embedding-3-small)
# Get from: https://platform.openai.com/api-keys
# OPENAI_API_KEY=sk-your-openai-key-here

# Ollama - Local LLM for background intelligence (summaries, scoring)
# Runs locally, no API key needed. Set to your Ollama host URL.
# OLLAMA_HOST=http://localhost:11434

# Brave Search - Enables web search
# Get from: https://brave.com/search/api/
# BRAVE_API_KEY=your-brave-search-key-here

# ═══════════════════════════════════════════════════════════════════════════════
# LLM Provider Configuration
# ═══════════════════════════════════════════════════════════════════════════════

# Override default LLM provider (options: deepseek, zhipu, ollama)
# DEFAULT_LLM_PROVIDER=deepseek

# For more fine-grained control, use ~/.mira/config.toml:
#   [llm]
#   background_provider = "deepseek"  # For summaries, briefings, pondering

# ═══════════════════════════════════════════════════════════════════════════════
# User Identity
# ═══════════════════════════════════════════════════════════════════════════════

# Override user identity for multi-user memory scoping
# By default, Mira uses git config user.email or system username
# MIRA_USER_ID=your-unique-id

# ═══════════════════════════════════════════════════════════════════════════════
# Advanced Options
# ═══════════════════════════════════════════════════════════════════════════════

# Disable all LLM features (use heuristic fallbacks only)
# MIRA_DISABLE_LLM=1

# Override embedding dimensions (default: 1536)
# MIRA_EMBEDDING_DIMENSIONS=1536

# Override Ollama model (default: llama3.3)
# OLLAMA_MODEL=llama3.3

# Enable fuzzy fallback when embeddings are unavailable (default: true)
# MIRA_FUZZY_FALLBACK=true

# Override project path detection
# MIRA_PROJECT_PATH=/path/to/project

